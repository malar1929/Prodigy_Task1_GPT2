%%writefile README.md
# Prodigy InfoTech Internship - Task 1
## Text Generation using GPT-2

**Name:** [ACTUAL NAME PODU DA]  # ğŸ’¡ CHANGE THIS!
**College:** [COLLEGE NAME]
**Internship ID:** [PRODIGY ID]
**Date:** 02/01/2024

## ğŸ“Œ Overview
Used GPT-2 model to generate coherent text based on given prompts using Hugging Face Transformers.

## ğŸ› ï¸ Technologies Used
- Python 3.x
- Hugging Face Transformers
- Google Colab
- Jupyter Notebook

## ğŸ“‚ Files Generated
1. `prodigy_task1_GPT2.ipynb` - Main code notebook
2. `gpt2_output.csv` - Single prompt output
3. `multiple_prompts.csv` - Multiple prompts output
4. `improved_output.html` - Enhanced HTML output
5. `output.html` - Simple HTML output
6. `prodigy_task1_final.zip` - Compressed submission

## ğŸš€ How to Run
1. Open `prodigy_task1_GPT2.ipynb` in Google Colab
2. Run all cells sequentially
3. Check outputs in CSV/HTML files

## ğŸ“Š Results
### Single Prompt:
**Prompt:** "Artificial Intelligence is"
**Generated:** "Artificial Intelligence is a topic that could only be addressed by bringing the world's leading technology into reality..."

### Multiple Prompts: (See multiple_prompts.csv)
- "The future of machine learning"
- "In the world of deep learning"
- "Natural Language Processing can"

## ğŸ¯ Learning Outcomes
- Learned to use Hugging Face Transformers library
- Implemented text generation with GPT-2
- Saved outputs in multiple formats (CSV, HTML)
- Created professional documentation
